

# WIKIT â€” AI-Based Financial Transaction Categorisation
Local, explainable, customisable ML pipeline for classifying raw financial transaction strings.

WIKIT is a fully in-house machine learning system that converts messy transaction text  
(e.g., `"AMAZON PAY *ORDER"`, `"SWIGGY * FOOD"`, `"HP PETROL PUMP"`)  
into clean, meaningful financial categories like **Groceries**, **Dining**, **Fuel**, etc.

No external APIs.  
No recurring billing.  
No vendor lock-in.  
Just your own classifier â€” fast, transparent, fully local.

---

# Features

### AI-Powered Transaction Categorisation
- Logistic Regression + TF-IDF  
- Cleaned + merchant-normalised features  
- Confidence scoring for every prediction  

### Evaluation & Metrics
- Macro F1: **0.93**  
- Accuracy: **0.93**  
- Per-class F1: **0.91â€“0.97**  
- Confusion matrix + classification report included  

### Data Preprocessing Pipeline
- Text cleaning  
- Merchant normalisation  
- Noise reduction  
- All rules configurable via JSON  

### Admin Tools
- Modify taxonomy (add/remove categories)  
- Change confidence thresholds  
- Inspect or clear merchant memory  
- Review and clear feedback CSV  

### Human-in-the-loop Feedback
- Low-confidence predictions highlight feedback
- User corrections populate:
  - `feedback.csv`
  - `memory.json` (merchantâ†’category overrides)

### Model Retraining (One Click)
- Merges base training data + feedback samples  
- Reweights feedback samples  
- Retrains LR model  
- Updates model + vectorizer  
- Triggered via **Refresh** tab in UI  

### Explainability
Token-level insights including:
- coefficient influence  
- perturbation sensitivity  
- combined impact score with UI bars  

### Batch Mode
- Upload CSV  
- Vectorised inference  
- Optional low-confidence â†’ â€œOtherâ€ routing  
- Downloadable results CSV  

### UI
- Streamlit  
- Custom dark-blue theme  
- Clean production-style layout  

---

# Technology Stack

| Component | Tech |
|----------|------|
| Preprocessing | Python, regex, merchant normaliser |
| Model | Logistic Regression (scikit-learn) |
| Vectoriser | TF-IDF (1â€“2 grams, 5000 features) |
| UI | Streamlit |
| Storage | JSON + CSV |
| Evaluation | scikit-learn + matplotlib |

---

# Documentation

- `docs/architecture.md`  
- `docs/dataset.md`  
- `docs/training_pipeline.md`  
- `docs/model.md`  
- `docs/explainability.md`  
- `docs/feedback_loop.md`  
- `docs/evaluation.md`  
- `docs/ui.md`  

---

# Project Structure
```
Wikit/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ dataset.md
â”‚   â”œâ”€â”€ evaluation.md
â”‚   â”œâ”€â”€ explainability_bias_mitigation.md
â”‚   â””â”€â”€ model.md
â”‚
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ config.json
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â”œâ”€â”€ batch_output.csv
â”‚   â”‚   â”œâ”€â”€ gomasaki.csv
â”‚   â”‚   â”œâ”€â”€ kaggle_sets.csv
â”‚   â”‚   â”œâ”€â”€ gen_data.py
â”‚   â”‚   â”œâ”€â”€ normalization.json
â”‚   â”‚   â”œâ”€â”€ taxonomy.json
â”‚   â”‚   â”œâ”€â”€ memory.json
â”‚   â”‚   â””â”€â”€ feedback.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ final_report.json
â”‚   â”‚   â”œâ”€â”€ final_report.md
â”‚   â”‚   â”œâ”€â”€ metrics_report.json
â”‚   â”‚   â”œâ”€â”€ performance_report.json
â”‚   â”‚   â””â”€â”€ robustness_report.json
â”‚   â”‚
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”œâ”€â”€ predict.log
â”‚   â”‚   â””â”€â”€ train.log
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ model.pkl
â”‚   â”‚   â””â”€â”€ vectorizer.pkl
â”‚   â”‚
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ preprocess.py
â”‚       â”œâ”€â”€ predict.py
â”‚       â”œâ”€â”€ explain.py
â”‚       â”œâ”€â”€ feedback.py
â”‚       â”œâ”€â”€ retrain.py
â”‚       â”œâ”€â”€ taxonomy.py
â”‚       â”œâ”€â”€ evaluate.py
â”‚       â”œâ”€â”€ performance.py
â”‚       â”œâ”€â”€ robustness.py
â”‚       â”œâ”€â”€ generate_report.py
â”‚       â””â”€â”€ train.py
â”‚
â””â”€â”€ ui/
    â”œâ”€â”€ app.py
    â””â”€â”€ .streamlit/
        â””â”€â”€ config.toml

```





# Running the App

Install dependencies:

```
pip install -r requirements.txt
```

Launch UI:
```
streamlit run project/ui/app.py

```
â¸»

Re-training

Base training:
```
python3 project/src/train.py
```
Human-feedback retraining:
```
python3 project/src/retrain.py

```
â¸»

Evaluation
```
python3 project/src/evaluate.py
```
Outputs:
	â€¢	evaluation/metrics_report.json
	â€¢	evaluation/confusion_matrix.png

â¸»
## Dataset Summary 

| Metric | Value |
| :--- | :--- |
| **Total samples** | 1000 |
| **Train** | 650 |
| **Test** | 352 |

---

### Train Distribution

* Entertainment: 104
* Groceries: 98
* Dining: 96
* Travel: 93
* Shopping: 91
* Bills: 88
* Fuel: 81

### Test Distribution

* Entertainment: 60
* Shopping: 55
* Groceries: 52
* Dining: 52
* Travel: 46
* Bills: 46
* Fuel: 41

---

## Performance Summary ğŸš€

* **Macro F1:** 0.93
* **Accuracy:** 0.93
* **Latency:** 0.12 ms / prediction
* **Throughput:** 8300+ predictions/sec
* **Explainability:** token-level contributions

---

## Checklist (PS Requirements) 

This solution includes:

* End-to-end **ML pipeline**
* **Evaluation** with reproducible metrics
* **Customisable taxonomy**
* **Explainability** features
* **Human feedback** mechanism
* **Batch inference**
* **One-click model retraining**
* **Real + synthetic data** usage

---

## Acknowledgements

Developed by **Nishant Bidhu** and **Swati Nim**
Created for **AnitaB.org India GHCI 25 Hackathon**
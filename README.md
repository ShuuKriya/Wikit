
# WIKIT â€” AI-Based Financial Transaction Categorisation  
**Local, explainable, customisable ML pipeline for classifying raw financial transaction strings.**

WIKIT is a fully in-house machine learning system that converts messy transaction text  
(e.g., `"AMAZON PAY *ORDER"`, `"SWIGGY * FOOD"`, `"HP PETROL PUMP"`)  
into clean, meaningful financial categories like **Groceries**, **Dining**, **Fuel**, etc.

No external APIs.  
No recurring billing.  
No vendor lock-in.  
Just **your own classifier**, fast and transparent.

---

#  Features

### ** AI-Powered Transaction Categorisation**
- Logistic Regression + TF-IDF  
- Cleaned + merchant-normalised features  
- Confidence scoring for every prediction  

### ** Evaluation & Metrics**
- Macro F1: **0.93**  
- Accuracy: **0.93**  
- Per-class F1: **0.91â€“0.97**  
- Confusion matrix + classification report included  

### ** Data Preprocessing Pipeline**
- Text cleaning  
- Merchant normalisation  
- Noise/stopword reduction  
- Normalisation rules configurable via JSON  

### ** Admin Tools**
- Modify taxonomy (add/remove categories)  
- Change confidence thresholds  
- Inspect or clear merchant memory  
- Review and clear feedback.csv  

### ** Human-in-the-loop Feedback**
- Low-confidence predictions automatically highlight feedback section  
- User corrections go into:
  - `feedback.csv`
  - `memory.json` (merchantâ†’category mapping)

### ** Model Retraining (One Click)**
- Merges base training data + feedback  
- Reweights feedback samples  
- Retrains LR model  
- Updates model + vectorizer live  
- Triggered via **Refresh** tab in UI  

### ** Explainability**
Token-level explanations showing:
- coefficient influence  
- perturbation sensitivity  
- combined impact score with progress bars  

### ** Batch Mode**
- Upload CSV  
- Vectorised inference  
- Configurable low-confidence handling  
- Download results CSV  

### ** UI**
- Built with Streamlit  
- Custom dark-blue theme  
- Clean, minimal, production-style layout  

---

# ðŸ”§ Technology Stack

| Component | Tech |
|----------|------|
| Preprocessing | Python, regex, custom merchant normaliser |
| Model | Logistic Regression (scikit-learn) |
| Vectoriser | TF-IDF (unigram + bigram, 5000 max features) |
| UI | Streamlit |
| Storage | JSON + CSV |
| Evaluation | scikit-learn + matplotlib |

---

#  Project Structure

Wikit/
â”‚
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ retrain.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â”œâ”€â”€ feedback.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ model.pkl
â”‚   â”‚   â””â”€â”€ vectorizer.pkl
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â”œâ”€â”€ normalization.json
â”‚   â”‚   â”œâ”€â”€ taxonomy.json
â”‚   â”‚   â”œâ”€â”€ memory.json
â”‚   â”‚   â””â”€â”€ feedback.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics_report.json
â”‚   â”‚   â””â”€â”€ confusion_matrix.png
â”‚   â”‚
â”‚   â”œâ”€â”€ config.json
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ requirements.txt

---

#  Running the App

Install dependencies:

```bash
pip install -r requirements.txt

Launch Streamlit UI:

streamlit run project/ui/app.py


â¸»

 Re-training

python3 project/src/train.py

Human-feedback based retraining:

python3 project/src/retrain.py


â¸»

 Evaluation

python3 project/src/evaluate.py

Outputs:
	â€¢	evaluation/metrics_report.json
	â€¢	evaluation/confusion_matrix.png

â¸»

 Dataset Summary

Total samples: 1000

Train Set (650 samples)

Entertainment    104
Groceries         98
Dining            96
Travel            93
Shopping          91
Bills             88
Fuel              81

Test Set (352 samples)

Entertainment    60
Shopping         55
Groceries        52
Dining           52
Travel           46
Bills            46
Fuel             41


â¸»

 Performance Summary
	â€¢	Macro F1: 0.93
	â€¢	Accuracy: 0.93
	â€¢	Latency: 0.12 ms / prediction
	â€¢	Throughput: 8300+ predictions/second
	â€¢	Explainability: token-level contributions

â¸»

 Demo Requirements (PS Guidelines)

This solution covers:

âœ” End-to-end pipeline
âœ” Evaluation with reproducible metrics
âœ” Customisable taxonomy
âœ” Explainability
âœ” Human feedback loop
âœ” Batch inference
âœ” Model retraining
âœ” Real + synthetic data usage

â¸»

 Acknowledgements

Developed by Shuu with ML engineering support from Smile ðŸ«¶
